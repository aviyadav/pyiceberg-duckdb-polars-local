# Iceberg-DuckDB-Polars Integration

A demonstration project showcasing the integration of Apache Iceberg, DuckDB, and Polars for efficient data lake operations. This project demonstrates how to:
- Create and manage Iceberg tables
- Write data using Polars DataFrames
- Read and query data using DuckDB
- Perform analytics with Polars

## Features

- ğŸ—„ï¸ **Apache Iceberg**: Table format for large analytic datasets
- ğŸ¦† **DuckDB**: In-process SQL OLAP database for analytics
- âš¡ **Polars**: Lightning-fast DataFrame library for Python
- ğŸ”„ **PyArrow**: Zero-copy data interchange between tools
- ğŸ“Š **End-to-End Workflow**: Write with Polars, query with DuckDB

## Prerequisites

- Python 3.13 or higher
- pip or uv package manager

## Installation

### Option 1: Using pip

1. Clone the repository:
```bash
git clone <repository-url>
cd iceberg-duckdb-polars
```

2. Create a virtual environment (recommended):
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install the package:
```bash
pip install -e .
```

### Option 2: Using uv (faster)

```bash
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -e .
```

## Project Structure

```
iceberg-duckdb-polars/
â”œâ”€â”€ iceberg_duckdb_polars.py    # Main script
â”œâ”€â”€ test_iceberg_duckdb_polars.py  # Test suite
â”œâ”€â”€ pyproject.toml              # Project configuration
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ TESTING.md                  # Testing guide
â””â”€â”€ iceberg_warehouse_001/      # Generated Iceberg warehouse (gitignored)
```

## Usage

### Running the Main Script

The main script demonstrates a complete workflow:

```bash
python iceberg_duckdb_polars.py
```

This will:
1. Create a local Iceberg catalog with SQLite backend
2. Define a schema with `id` (Integer) and `name` (String) fields
3. Create a namespace and table
4. Write sample data using Polars DataFrame
5. Read and query data using DuckDB
6. Read and display data using Polars

### Expected Output

```
Data read from Iceberg table using DuckDB:
   id     name
0   1    Alice
1   2      Bob
2   3  Charlie

Data read from Iceberg table using Polars:
shape: (3, 2)
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ id  â”† name    â”‚
â”‚ --- â”† ---     â”‚
â”‚ i32 â”† str     â”‚
â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡
â”‚ 1   â”† Alice   â”‚
â”‚ 2   â”† Bob     â”‚
â”‚ 3   â”† Charlie â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Code Examples

### Creating an Iceberg Table

```python
from pyiceberg.catalog import load_catalog
from pyiceberg.schema import Schema
from pyiceberg.types import IntegerType, StringType, NestedField

# Create catalog
catalog = load_catalog("local", **{
    "type": "sql",
    "uri": "sqlite:///warehouse/catalog.db",
    "warehouse": "warehouse_path"
})

# Define schema
schema = Schema(
    NestedField(field_id=1, name="id", field_type=IntegerType(), required=False),
    NestedField(field_id=2, name="name", field_type=StringType(), required=False),
)

# Create table
catalog.create_namespace("default")
table = catalog.create_table("default.my_table", schema)
```

### Writing Data with Polars

```python
import polars as pl

# Create DataFrame
data = pl.DataFrame({
    "id": [1, 2, 3],
    "name": ["Alice", "Bob", "Charlie"]
}).with_columns(pl.col("id").cast(pl.Int32))

# Write to Iceberg
table.append(data.to_arrow())
```

### Querying with DuckDB

```python
import duckdb

con = duckdb.connect()
arrow_table = table.scan().to_arrow()
con.register('my_table', arrow_table)
result = con.execute("SELECT * FROM my_table WHERE id > 1").fetchdf()
```

### Reading with Polars

```python
polars_df = pl.from_arrow(table.scan().to_arrow())
filtered = polars_df.filter(pl.col("id") > 1)
```

## Testing

### Install Test Dependencies

```bash
pip install -e ".[dev]"
```

### Run All Tests

```bash
pytest test_iceberg_duckdb_polars.py -v
```

### Run with Coverage

```bash
pytest test_iceberg_duckdb_polars.py --cov=iceberg_duckdb_polars --cov-report=html
```

For detailed testing information, see [TESTING.md](TESTING.md).

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Polars    â”‚  Write DataFrames
â”‚  DataFrame  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   PyArrow    â”‚  Zero-copy bridge
                    â”‚    Table     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Iceberg    â”‚  Table format
                    â”‚    Table     â”‚  with metadata
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   DuckDB     â”‚        â”‚   Polars     â”‚
        â”‚  SQL Engine  â”‚        â”‚  DataFrame   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Dependencies

- **pyiceberg** (â‰¥0.10.0): Apache Iceberg Python implementation
- **polars** (â‰¥1.35.1): Fast DataFrame library
- **duckdb** (â‰¥1.4.1): In-process SQL OLAP database
- **pyarrow** (â‰¥22.0.0): Columnar data format
- **sqlalchemy** (â‰¥2.0.44): SQL toolkit for catalog
- **pandas** (â‰¥2.3.3): Data manipulation (for DuckDB output)
- **numpy** (â‰¥2.3.4): Numerical computing

## Troubleshooting

### Field Mismatch Errors

If you encounter "Mismatch in fields" errors:
- Ensure all fields in the schema have `required=False` for nullable fields
- Match the field types between Polars and Iceberg schema
- Cast Polars columns to the correct types (e.g., `.cast(pl.Int32)`)

### Import Errors

If you get module not found errors:
```bash
pip install --upgrade -e .
```

### Virtual Environment Issues

If the virtual environment is incomplete:
```bash
rm -rf .venv
python -m venv .venv
source .venv/bin/activate
pip install -e .
```

## Performance Considerations

- **Polars**: Optimized for speed with lazy evaluation and parallel processing
- **DuckDB**: Vectorized query execution for fast analytics
- **Iceberg**: Efficient metadata handling for large-scale data lakes
- **PyArrow**: Zero-copy data sharing between components

## Use Cases

1. **Data Lake Management**: Use Iceberg for ACID transactions and time travel
2. **Fast Analytics**: Leverage DuckDB for SQL queries on Iceberg tables
3. **ETL Pipelines**: Use Polars for high-performance data transformations
4. **Multi-Tool Integration**: Combine the strengths of all three tools

## Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

## License

[Add your license here]

## Resources

- [Apache Iceberg Documentation](https://iceberg.apache.org/)
- [DuckDB Documentation](https://duckdb.org/docs/)
- [Polars Documentation](https://pola.rs/)
- [PyArrow Documentation](https://arrow.apache.org/docs/python/)

## Contact

[Add your contact information here]
